作业1（约400字）：后端开发与算法开发需要做什么？
在客服工作台的 FAQ 场景中，系统目标是用“用户问题→匹配历史问题→返回对应答案”来代替人工客服。因此，后端开发需要完成 FAQ 类目管理与 FAQ 内容管理两大功能，包括一级类目、二级类目、FAQ 问题、相似问题、答案、生效时间等字段的增删改查，并提供统一 API 给前端调用。为了支撑检索和匹配，还需要设计数据库结构，例如类目表、FAQ 主表、相似问表、答案表以及 FAQ 状态表（生效/失效）。此外，后端要支持导入、批量更新、权限控制、日志审计、以及高并发查询的缓存策略。
算法开发侧重点在“文本相似度匹配”。最核心的方案是使用 BERT 进行句向量编码：将 FAQ 的标准问题及其相似问统一编码为向量，并写入向量库或索引；在线阶段对用户输入编码后，与 FAQ 向量做相似度检索，返回 Top-K 最相似问题的答案。BERT 可采用 Sentence-BERT 或 SimCSE 这类专门用于语义匹配的模型，比直接用 BERT [CLS] 更稳定。是否需要大模型取决于需求：若仅做 FAQ 检索，BERT/向量检索已足够；若需要“多轮对话、意图识别、答案生成与改写”，才更适合引入大模型，但成本与可控性需要额外评估。

作业2（约400字）：BERT 编码与相似度计算方案
本方案采用 BERT 类模型实现 FAQ 语义检索。离线阶段先对知识库中的 FAQ 标准问题与相似问题进行文本预处理（去噪、统一符号、长度截断），再输入 BERT 编码器获得句向量表示。为了提升语义一致性，推荐使用 Sentence-BERT/SimCSE 结构：通过 pooling（mean pooling 或 CLS pooling）得到固定维度向量，并进行 L2 归一化。随后将向量写入向量索引（如 Faiss / Milvus / ElasticSearch dense vector）。在线阶段用户输入问题后，同样经过 BERT 编码得到向量，与索引中的 FAQ 向量计算余弦相似度，返回 Top-K 候选问题。系统再结合 FAQ 生效时间、类目过滤、阈值策略（如 cos>0.75）确定最终命中问题，并返回对应答案。若未达到阈值，则返回兜底回复或转人工。该方案优点是语义鲁棒性强、可扩展性好，并能支持持续增量更新（新增 FAQ 后离线编码并更新索引）。
