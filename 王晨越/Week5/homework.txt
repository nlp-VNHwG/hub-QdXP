问题1:阅读上面的客服工作台的说明，总结我们自己作为后端开发和算法开发的角色，我们需要做什么？
需要构建数据库，首先需要构建一个类目表，这个表用来管理不同层级之间的关系，例如类目ID，类目名称，父类类目ID，当前层级，创建时间等。第二个表可以创建类似于标签表，标签id，标签名称。第三个表需要创建一个FAQ的信息储存表，例如可以储存问题ID，问题，答案，生效时间，答案类型，所属标签id，所属标签名称，关联问题ID。第四个表就是存储相似问题表，相似问题ID，相似问题，关联问题ID。第五个就是要有向量数据库。在模型选择上可以使用BERT模型，需要将每个unique的问题ID的问题，和在存储相似问题表里面的每个关联问题ID的相似问题全部取出来作为BERT输入，存到向量数据库，每个向量对应一个关联问题。当有新的问题产生的时候，作为输入得到结果在对比哪个相似。大模型在这个任务中不作为主要进行使用，但是可以作为工具来丰富语料库，好比可以让大模型生成类似的问题，为了更好的匹配用户结果。也可以用来优化回复，在得到具体答案后传入大模型进行答案优化。

问题2: 如何使用bert 进行文本编码，并且使用bert 进行相似度计算，需要写清楚技术方案；
首先在文本编码阶段，后端需从 FAQ 信息表 与 相似问题表 中提取所有文本描述，包括标准问题与相似问题，并将其统一构造为 [CLS] 标准问题 [SEP] 的输入格式或者[CLS] 相似问题 [SEP] 的输入格式。算法侧通过 BERT 模型提取最后一层输出的第一个位置 [CLS] 隐藏状态向量（通常为 768维），该向量能够高度概括整句的全局语义特征。每一个独立编码后的向量，如标准问向量或相似问向量 ，都会与数据库中的 关联问题ID 进行强绑定。当进入实时相似度计算阶段时，用户输入的提问 会通过同一 BERT 模型实时生成其对应的 [CLS] 向量 。随后，系统在向量数据库中检索与 
最接近的存量向量，核心逻辑是计算两者之间的 余弦相似度 (Cosine Similarity)。该分值越接近1，证明语义匹配度越高。最终，系统定位到相似度最高的向量记录，提取其背后的 关联问题ID，并由后端从数据库中调取该 ID 对应的标准答案返回给用户。