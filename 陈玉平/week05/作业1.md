# 客服工作台技术方案设计文档

## 一、系统概述

### 1.1 功能需求
- **功能1**: FAQ类目管理(一级类目、二级类目、对应的FAQ信息)
- **功能2**: FAQ录入和管理(待选提问、相似提问、生效时间、对应回答)

### 1.2 使用场景
代替人工客服,用户的提问直接与历史的提问进行相似度匹配,将最相似提问的回答返回给用户。

---

## 二、角色分工与职责

### 2.1 后端开发职责

#### 任务1: 数据库设计与实现
**具体工作:**
- 设计FAQ类目表(一级类目、二级类目关系)
- 设计FAQ问答表(问题、答案、生效时间、状态等)
- 设计相似问题表(问题ID、相似问题列表)
- 设计向量索引表(问题ID、向量embedding)
- 编写数据库迁移脚本和初始化脚本

**技术栈:** MySQL/PostgreSQL + Redis(缓存)

#### 任务2: RESTful API开发
**具体工作:**
- 类目管理接口(CRUD操作)
- FAQ管理接口(增删改查、批量导入)
- 问答匹配接口(接收用户提问,返回最佳答案)
- 相似问题推荐接口
- 数据统计接口(问答命中率、未匹配问题统计)

**技术栈:** Spring Boot / Flask / FastAPI

#### 任务3: 向量存储与检索服务
**具体工作:**
- 集成向量数据库(如Milvus、Faiss、Elasticsearch)
- 实现向量的增删改查接口
- 实现向量相似度检索(Top-K检索)
- 向量索引的更新和维护机制
- 缓存热门问题的向量

**技术栈:** Milvus / Faiss / Elasticsearch with Vector Plugin

#### 任务4: 系统集成与性能优化
**具体工作:**
- 实现算法服务的调用(向算法服务发送文本,获取embedding)
- 缓存策略设计(热门问题缓存、向量缓存)
- 接口性能优化(响应时间<500ms)
- 日志记录和监控埋点
- 异常处理和降级策略

### 2.2 算法开发职责

#### 任务1: BERT模型选型与部署
**具体工作:**
- 选择合适的BERT预训练模型(中文场景推荐: bert-base-chinese, chinese-roberta-wwm-ext)
- 评估是否需要领域微调(如果有大量客服领域数据)
- 模型压缩和优化(量化、蒸馏,提升推理速度)
- 模型部署(TorchServe / TensorFlow Serving / Triton)
- 模型版本管理

**技术选型:**
- 基础模型: `bert-base-chinese` 或 `hfl/chinese-roberta-wwm-ext`
- 如果追求更好效果: `hfl/chinese-bert-wwm-ext` 或微调BERT
- 如果追求速度: 使用轻量级模型如 `distilbert` 或 `TinyBERT`

#### 任务2: 文本Embedding服务开发
**具体工作:**
- 开发文本向量化服务(接收文本,返回embedding向量)
- 批量向量化接口(用于历史数据初始化)
- Embedding维度标准化(如768维或降维到256/512维)
- 推理性能优化(批处理、GPU加速)
- 提供gRPC/HTTP接口供后端调用

#### 任务3: 相似度匹配算法实现
**具体工作:**
- 实现余弦相似度计算
- 设计相似度阈值策略(如>0.85返回答案,0.7-0.85推荐相似问题,<0.7返回未匹配)
- 实现多候选答案排序逻辑
- A/B测试不同相似度计算方法(余弦/欧氏距离/点积)

#### 任务4: 模型效果评估与迭代
**具体工作:**
- 构建测试数据集(标注问题对的相似度)
- 评估指标: 准确率、召回率、F1-score、MRR(Mean Reciprocal Rank)
- 对比不同模型的效果
- 收集badcase并持续优化
- 定期重训练模型(如果有领域数据积累)

---

## 三、技术架构设计

### 3.1 数据库设计

**1. 类目表 (category)**
**2. FAQ问答表 (faq)**

**3. 相似问题表 (similar_question)**

**4. 问题向量表 (question_embedding)**

**5. 用户提问日志表 (user_query_log)**

### 3.2 模型对比

#### 方案对比:

| 方案 | 模型 | 优点 | 缺点 | 推荐场景 |
|------|------|------|------|----------|
| **方案1: BERT Embedding + 向量检索** | bert-base-chinese | 效果好,语义理解强 | 需要部署模型服务 | 中小规模FAQ(1万以内) |
| **方案2: Sentence-BERT** | sentence-transformers | 专门优化句子相似度 | 需要训练数据 | 有标注数据的场景 |
| **方案3: 大模型Embedding** | text-embedding-ada-002 (OpenAI) | 效果最好,零配置 | 成本高,依赖第三方 | 快速验证MVP |
| **方案4: 轻量级模型** | TinyBERT / DistilBERT | 推理速度快 | 效果略差 | 大规模FAQ,追求速度 |

**推荐选择: 方案1(BERT) + 方案3(大模型)结合**
- 初期使用BERT自建服务,成本可控
- 后期如果效果不足,可升级到大模型Embedding

### 3.3 BERT使用

#### 完整流程:

**步骤1: 离线阶段 - 向量化所有FAQ**

**步骤2: 在线阶段 - 用户提问匹配**

**步骤3: 增量更新**

### 3.4 是否需要使用大模型

#### 分析:

**不使用大模型(仅BERT):**
- ✅ 优点: 成本低,可控性强,响应快
- ❌ 缺点: 语义理解能力有限,可能需要大量相似问题样本

**使用大模型(如GPT/Claude):**
- ✅ 优点: 语义理解能力强,可以做意图识别和问题改写
- ❌ 缺点: 成本高,响应慢,可能产生幻觉

**推荐方案: 混合架构**

```
用户提问 
   ↓
[BERT向量匹配] → 相似度 > 0.85 → 直接返回答案 ✓
   ↓ 相似度 0.5-0.85
[大模型改写/意图识别] → 重新匹配 → 返回答案
   ↓ 相似度 < 0.5
[大模型生成答案] → 人工审核 → 加入FAQ库
```

**大模型的使用场景:**
1. **问题改写**: 将口语化问题改写为标准问题
2. **意图识别**: 识别用户真实意图
3. **兜底方案**: 当向量匹配失败时,用大模型生成答案
4. **FAQ生成**: 辅助生成相似问题

---

## 四、其他需要做的工作

### 任务5: 管理后台开发(后端)
**具体工作:**
- 开发FAQ管理后台界面的后端接口
- 实现批量导入功能(Excel/CSV导入FAQ)
- 实现FAQ审核流程(待审核→已发布)
- 数据导出功能(导出FAQ数据)
- 权限管理(管理员/普通用户)
- 操作日志记录

**技术要点:**
- 使用POI/pandas处理Excel导入
- 实现RBAC权限模型
- 提供批量操作接口

### 任务6: 未匹配问题挖掘与分析(算法)
**具体工作:**
- 统计高频未匹配问题
- 聚类分析相似的未匹配问题
- 自动生成FAQ建议(基于高频未匹配问题)
- 识别问题意图分布
- 生成运营报表(问题覆盖率、匹配率趋势)


---


## 六、技术选型总结

| 组件 | 推荐技术 | 备选方案 |
|------|----------|----------|
| **后端框架** | Spring Boot / FastAPI | Flask / Django |
| **数据库** | MySQL 8.0+ | PostgreSQL |
| **向量数据库** | Milvus / Faiss | Elasticsearch Vector |
| **缓存** | Redis | Memcached |
| **BERT模型** | bert-base-chinese | chinese-roberta-wwm-ext |
| **模型部署** | TorchServe / FastAPI | TensorFlow Serving |
| **大模型(可选)** | OpenAI API / Claude API | 阿里通义/文心一言 |

---

## 七、关键指标定义

### 7.1 算法指标
- **匹配率**: 成功匹配的问题 / 总问题数 (目标: >85%)
- **准确率**: 用户反馈有用的答案 / 返回答案数 (目标: >90%)
- **平均相似度**: 匹配成功时的平均相似度分数
- **响应时间**: P99 < 500ms

### 7.2 业务指标
- **FAQ覆盖率**: 有FAQ的类目 / 总类目数
- **问题解决率**: 不需要人工介入的问题比例
- **用户满意度**: 用户点赞率

---

## 八、风险与挑战

### 8.1 技术风险
- **冷启动问题**: 初期FAQ数量少,匹配率低
  - **解决方案**: 预先准备核心FAQ库,逐步扩充

- **同义词问题**: "修改密码"vs"更改密码"
  - **解决方案**: BERT本身有一定同义词理解能力,或补充同义词词典

### 8.2 性能挑战
- **大规模向量检索**: FAQ超过10万时检索变慢
  - **解决方案**: 使用Milvus分片 + 类目预过滤

- **模型推理延迟**: BERT推理时间100-200ms
  - **解决方案**: 批处理 + GPU加速 + 模型量化
